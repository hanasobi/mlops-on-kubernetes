apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-dashboard-triton
  namespace: ai-platform
  labels:
    grafana_dashboard: "1"
data:
  triton-production.json: |
    {
      "annotations": { "list": [] },
      "editable": true,
      "fiscalYearStartMonth": 0,
      "graphTooltip": 1,
      "links": [],
      "panels": [
        {
          "collapsed": false,
          "gridPos": { "h": 1, "w": 24, "x": 0, "y": 0 },
          "id": 100,
          "title": "Inference",
          "type": "row"
        },
        {
          "datasource": { "type": "prometheus", "uid": "${datasource}" },
          "fieldConfig": {
            "defaults": {
              "color": { "mode": "palette-classic" },
              "custom": {
                "axisBorderShow": false,
                "axisCenteredZero": false,
                "axisLabel": "req/s",
                "fillOpacity": 10,
                "lineWidth": 2,
                "showPoints": "never"
              },
              "unit": "reqps"
            },
            "overrides": []
          },
          "gridPos": { "h": 8, "w": 8, "x": 0, "y": 1 },
          "id": 1,
          "options": { "legend": { "displayMode": "list", "placement": "bottom" }, "tooltip": { "mode": "multi" } },
          "title": "Inference Request Rate",
          "type": "timeseries",
          "targets": [
            {
              "datasource": { "type": "prometheus", "uid": "${datasource}" },
              "expr": "sum(rate(nv_inference_request_success{job=\"triton-inference\"}[$__rate_interval])) by (model)",
              "legendFormat": "{{model}} success"
            },
            {
              "datasource": { "type": "prometheus", "uid": "${datasource}" },
              "expr": "sum(rate(nv_inference_request_failure{job=\"triton-inference\"}[$__rate_interval])) by (model)",
              "legendFormat": "{{model}} failure"
            }
          ]
        },
        {
          "datasource": { "type": "prometheus", "uid": "${datasource}" },
          "fieldConfig": {
            "defaults": {
              "color": { "mode": "palette-classic" },
              "custom": {
                "axisBorderShow": false,
                "axisCenteredZero": false,
                "axisLabel": "",
                "fillOpacity": 10,
                "lineWidth": 2,
                "showPoints": "never"
              },
              "unit": "ms"
            },
            "overrides": []
          },
          "gridPos": { "h": 8, "w": 8, "x": 8, "y": 1 },
          "id": 2,
          "options": { "legend": { "displayMode": "list", "placement": "bottom" }, "tooltip": { "mode": "multi" } },
          "title": "Inference Latency (Request Duration)",
          "type": "timeseries",
          "targets": [
            {
              "datasource": { "type": "prometheus", "uid": "${datasource}" },
              "expr": "rate(nv_inference_request_duration_us{job=\"triton-inference\"}[$__rate_interval]) / rate(nv_inference_request_success{job=\"triton-inference\"}[$__rate_interval]) / 1000",
              "legendFormat": "{{model}} avg (ms)"
            }
          ]
        },
        {
          "datasource": { "type": "prometheus", "uid": "${datasource}" },
          "fieldConfig": {
            "defaults": {
              "color": { "mode": "palette-classic" },
              "custom": {
                "axisBorderShow": false,
                "axisCenteredZero": false,
                "axisLabel": "",
                "fillOpacity": 10,
                "lineWidth": 2,
                "showPoints": "never"
              },
              "unit": "none"
            },
            "overrides": []
          },
          "gridPos": { "h": 8, "w": 8, "x": 16, "y": 1 },
          "id": 3,
          "options": { "legend": { "displayMode": "list", "placement": "bottom" }, "tooltip": { "mode": "multi" } },
          "title": "Total Inference Count",
          "type": "timeseries",
          "targets": [
            {
              "datasource": { "type": "prometheus", "uid": "${datasource}" },
              "expr": "nv_inference_count{job=\"triton-inference\"}",
              "legendFormat": "{{model}}"
            }
          ]
        },
        {
          "collapsed": false,
          "gridPos": { "h": 1, "w": 24, "x": 0, "y": 9 },
          "id": 101,
          "title": "Queue",
          "type": "row"
        },
        {
          "datasource": { "type": "prometheus", "uid": "${datasource}" },
          "fieldConfig": {
            "defaults": {
              "color": { "mode": "palette-classic" },
              "custom": {
                "axisBorderShow": false,
                "axisCenteredZero": false,
                "axisLabel": "",
                "fillOpacity": 10,
                "lineWidth": 2,
                "showPoints": "never"
              },
              "unit": "ms"
            },
            "overrides": []
          },
          "gridPos": { "h": 8, "w": 12, "x": 0, "y": 10 },
          "id": 4,
          "options": { "legend": { "displayMode": "list", "placement": "bottom" }, "tooltip": { "mode": "multi" } },
          "title": "Queue Duration (avg per request)",
          "type": "timeseries",
          "targets": [
            {
              "datasource": { "type": "prometheus", "uid": "${datasource}" },
              "expr": "rate(nv_inference_queue_duration_us{job=\"triton-inference\"}[$__rate_interval]) / rate(nv_inference_request_success{job=\"triton-inference\"}[$__rate_interval]) / 1000",
              "legendFormat": "{{model}} queue (ms)"
            }
          ]
        },
        {
          "datasource": { "type": "prometheus", "uid": "${datasource}" },
          "fieldConfig": {
            "defaults": {
              "color": { "mode": "palette-classic" },
              "custom": {
                "axisBorderShow": false,
                "axisCenteredZero": false,
                "axisLabel": "",
                "fillOpacity": 10,
                "lineWidth": 2,
                "showPoints": "never"
              },
              "unit": "ms"
            },
            "overrides": []
          },
          "gridPos": { "h": 8, "w": 12, "x": 12, "y": 10 },
          "id": 5,
          "options": { "legend": { "displayMode": "list", "placement": "bottom" }, "tooltip": { "mode": "multi" } },
          "title": "Compute Duration (avg per request)",
          "type": "timeseries",
          "targets": [
            {
              "datasource": { "type": "prometheus", "uid": "${datasource}" },
              "expr": "rate(nv_inference_compute_infer_duration_us{job=\"triton-inference\"}[$__rate_interval]) / rate(nv_inference_request_success{job=\"triton-inference\"}[$__rate_interval]) / 1000",
              "legendFormat": "{{model}} compute (ms)"
            }
          ]
        },
        {
          "collapsed": false,
          "gridPos": { "h": 1, "w": 24, "x": 0, "y": 18 },
          "id": 102,
          "title": "Infrastructure (Pod Resources)",
          "type": "row"
        },
        {
          "datasource": { "type": "prometheus", "uid": "${datasource}" },
          "fieldConfig": {
            "defaults": {
              "color": { "mode": "palette-classic" },
              "custom": {
                "axisBorderShow": false,
                "axisCenteredZero": false,
                "axisLabel": "",
                "fillOpacity": 30,
                "lineWidth": 2,
                "showPoints": "never"
              },
              "unit": "short"
            },
            "overrides": []
          },
          "gridPos": { "h": 8, "w": 12, "x": 0, "y": 19 },
          "id": 6,
          "options": { "legend": { "displayMode": "list", "placement": "bottom" }, "tooltip": { "mode": "multi" } },
          "title": "Pod CPU Usage (cores)",
          "type": "timeseries",
          "targets": [
            {
              "datasource": { "type": "prometheus", "uid": "${datasource}" },
              "expr": "sum(rate(container_cpu_usage_seconds_total{namespace=\"ml-models\", pod=~\"triton-inference.*\", container=\"triton\"}[$__rate_interval])) by (pod)",
              "legendFormat": "{{pod}}"
            }
          ]
        },
        {
          "datasource": { "type": "prometheus", "uid": "${datasource}" },
          "fieldConfig": {
            "defaults": {
              "color": { "mode": "palette-classic" },
              "custom": {
                "axisBorderShow": false,
                "axisCenteredZero": false,
                "axisLabel": "",
                "fillOpacity": 30,
                "lineWidth": 2,
                "showPoints": "never"
              },
              "unit": "bytes"
            },
            "overrides": []
          },
          "gridPos": { "h": 8, "w": 12, "x": 12, "y": 19 },
          "id": 7,
          "options": { "legend": { "displayMode": "list", "placement": "bottom" }, "tooltip": { "mode": "multi" } },
          "title": "Pod Memory Usage",
          "type": "timeseries",
          "targets": [
            {
              "datasource": { "type": "prometheus", "uid": "${datasource}" },
              "expr": "sum(container_memory_working_set_bytes{namespace=\"ml-models\", pod=~\"triton-inference.*\", container=\"triton\"}) by (pod)",
              "legendFormat": "{{pod}}"
            }
          ]
        }
      ],
      "schemaVersion": 39,
      "tags": ["triton", "ml", "production"],
      "templating": {
        "list": [
          {
            "current": { "selected": false, "text": "Prometheus", "value": "prometheus" },
            "hide": 0,
            "includeAll": false,
            "label": "Data Source",
            "multi": false,
            "name": "datasource",
            "options": [],
            "query": "prometheus",
            "refresh": 1,
            "type": "datasource"
          }
        ]
      },
      "time": { "from": "now-1h", "to": "now" },
      "title": "Triton Production",
      "uid": "triton-production"
    }
